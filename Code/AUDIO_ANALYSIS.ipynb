{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fichier original \n",
    "\n",
    "https://drive.google.com/file/d/1u4S5ILT6fCFk8J3Nkpyom9-pKjETI_u0/view?usp=drive_web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fichier augmenté\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "from langdetect import detect\n",
    "import csv\n",
    "import os\n",
    "import langid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio_file = \"C:\\\\Users\\\\angej\\\\Desktop\\\\Multilingual\\\\Beware_of_false_experts\\\\2020_03_25_000030-ci-covid19-unesco_msg03_eng.wav\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load audio files with librosa\n",
    "Audio_file, sr = librosa.load(Audio_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic information regarding audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Audio_file.shape)\n",
    "\n",
    "# duration in seconds of 1 sample\n",
    "sample_duration = 1 / sr\n",
    "print(f\"One sample lasts for {sample_duration:6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALISATION DES CARACTERISTIQUES AUDIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un graphique\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(Audio_file, label='Audio Signal')\n",
    "plt.title('Audio Signal')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.xlabel('Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un graphique\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Définir la condition pour les amplitudes à colorer en rouge\n",
    "red_condition = Audio_file > np.percentile(Audio_file, 99.50)  # Les 5% d'amplitudes les plus élevées\n",
    "\n",
    "# Tracer les points de données en rouge si la condition est vraie\n",
    "plt.plot(np.where(red_condition, Audio_file, np.nan), color='red', label='High Amplitude')\n",
    "\n",
    "# Tracer les autres points de données en bleu\n",
    "plt.plot(np.where(~red_condition, Audio_file, np.nan), label='Normal Amplitude')\n",
    "\n",
    "plt.title('Audio Signal')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.xlabel('Time')\n",
    "plt.legend(\"2020_03_25_000030-ci-covid19-unesco_msg03_eng.wav\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir le tempo et les beats\n",
    "tempo, beat_frames = librosa.beat.beat_track(y=Audio_file, sr=sr)\n",
    "\n",
    "# Obtenir le spectre de Mel\n",
    "S = librosa.feature.melspectrogram(y=Audio_file, sr=sr, n_mels=128, fmax=8000)\n",
    "\n",
    "# Visualiser le spectre de Mel\n",
    "plt.figure(figsize=(10, 4))\n",
    "S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "librosa.display.specshow(S_dB, x_axis='time', y_axis='mel', sr=sr, fmax=8000)\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Spectrogramme de Mel')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Tempo: {tempo}')\n",
    "print(f'Beat frames: {beat_frames}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effectuer la STFT\n",
    "D = librosa.stft(Audio_file)\n",
    "\n",
    "# Convertir en amplitude\n",
    "D_amp = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "\n",
    "# Visualiser l'analyse temporelle et fréquentielle\n",
    "plt.figure(figsize=(15, 10))\n",
    "librosa.display.specshow(D_amp, sr=sr, x_axis='time', y_axis='log')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Spectrogramme STFT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir le ton chromatique\n",
    "C = librosa.feature.chroma_cqt(y=Audio_file, sr=sr)\n",
    "\n",
    "# Obtenir le contraste spectral\n",
    "contrast = librosa.feature.spectral_contrast(S=S, sr=sr)\n",
    "\n",
    "# Obtenir les statistiques\n",
    "mean_S = np.mean(S)\n",
    "std_S = np.std(S)\n",
    "mean_C = np.mean(C)\n",
    "std_C = np.std(C)\n",
    "mean_contrast = np.mean(contrast)\n",
    "std_contrast = np.std(contrast)\n",
    "\n",
    "print(f'Standard deviation Mel spectrogram: {std_S}')\n",
    "print(f'Mean Chroma: {mean_C}')\n",
    "print(f'Standard deviation Chroma: {std_C}')\n",
    "print(f'Mean Spectral contrast: {mean_contrast}')\n",
    "print(f'Standard deviation Spectral contrast: {std_contrast}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une figure et des axes\n",
    "fig, axs = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Visualiser le ton chromatique\n",
    "axs[0].bar(['Mean', 'Standard Deviation'], [mean_C, std_C])\n",
    "axs[0].set_title('Chroma')\n",
    "\n",
    "# Visualiser le contraste spectral\n",
    "axs[1].bar(['Mean', 'Standard Deviation'], [mean_contrast, std_contrast])\n",
    "axs[1].set_title('Spectral Contrast')\n",
    "\n",
    "\n",
    "# Afficher la figure\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un DataFrame avec les mesures que vous avez calculées\n",
    "df = pd.DataFrame({\n",
    "    'Tempo': [tempo],\n",
    "    'Mean Mel spectrogram': [mean_S],\n",
    "    'Standard deviation Mel spectrogram': [std_S],\n",
    "    'Mean Chroma': [mean_C],\n",
    "    'Standard deviation Chroma': [std_C],\n",
    "    'Mean Spectral contrast': [mean_contrast],\n",
    "    'Standard deviation Spectral contrast': [std_contrast]\n",
    "})\n",
    "\n",
    "# Ajouter des colonnes pour le sexe et la langue\n",
    "df['Transcription'] = ['']\n",
    "df['Sexe'] = [''] \n",
    "df['Langue'] = ['']  \n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RECONNAISSANCE DE GENRE ET DE SEXE ET  TRANSCRIPTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "\n",
    "\n",
    "# Chemin pour sauvegarder le fichier CSV\n",
    "csv_file = df = \"C:\\\\Users\\\\angej\\\\Desktop\\\\Multilingual\\\\Code\\\\dataframe.csv\"\n",
    "\n",
    "# Créer un recognizer de la librairie speech_recognition\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# AudioFile pour chaque fichier audio\n",
    "audio_files = [#'C:\\\\Users\\\\angej\\\\Desktop\\\\Multilingual\\\\COVID_19_vaccine_side_effects_to_expect\\\\03_covid_19_vaccine_side_effects_to_expect_en.mp3'\n",
    "               'C:\\\\Users\\\\angej\\\\Desktop\\\\Multilingual\\\\Gauge your emotional reaction\\\\2020-03-25-000040-ci-covid19-unesco_msg04_eng.wav']\n",
    "\n",
    "# Créer une liste pour stocker les nouvelles données\n",
    "nouvelles_donnees = []\n",
    "\n",
    "for audio_file in audio_files:\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio_data = r.record(source)\n",
    "        text = r.recognize_google(audio_data)\n",
    "        \n",
    "        # Utiliser langid pour déterminer la langue\n",
    "        lang, _ = langid.classify(text)\n",
    "        \n",
    "        # Ajouter les nouvelles données à la liste\n",
    "        nouvelles_donnees.append({'Audio': audio_file,\n",
    "                                  'Transcription': text,\n",
    "                                  'Langue': lang ,\n",
    "                                  'Tempo': tempo,\n",
    "                                  'Mean Mel spectrogram':mean_S,'Standard deviation Mel spectrogram': std_S,\n",
    "                                  'Mean Chroma':mean_C})\n",
    "try:\n",
    "    with open(csv_file, 'r') as file:\n",
    "        # Vérifier si le fichier CSV existe déjà\n",
    "        if os.path.isfile(csv_file):\n",
    "            # Charger le DataFrame depuis le fichier CSV\n",
    "            df = pd.read_csv(csv_file)\n",
    "            \n",
    "            # Ajouter les nouvelles données au DataFrame existant\n",
    "            if not df.empty:\n",
    "                # Convertir les nouvelles données en un DataFrame\n",
    "                nouvelles_donnees_df = pd.DataFrame(nouvelles_donnees)\n",
    "                \n",
    "                # Ajouter les nouvelles données au DataFrame existant\n",
    "                df = pd.concat([df, nouvelles_donnees_df], ignore_index=True, axis=0)\n",
    "            else:\n",
    "                # Créer un DataFrame avec les nouvelles données si le DataFrame est vide\n",
    "                df = pd.DataFrame(nouvelles_donnees)\n",
    "        else:\n",
    "            # Créer un DataFrame avec les nouvelles données si le fichier n'existe pas\n",
    "            df = pd.DataFrame(nouvelles_donnees)\n",
    "except Exception as e:\n",
    "    print(\"Une erreur est survenue lors de la lecture du fichier CSV :\", e)\n",
    "\n",
    "# Sauvegarder le DataFrame complet dans un fichier CSV\n",
    "df.to_csv(csv_file, index=False)\n",
    "\n",
    "# Afficher le DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA AUGMENTATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series(data):\n",
    "    fig = plt.figure(figsize=(14, 8))\n",
    "    plt.title('Audio Signal ')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.plot(np.linspace(0, 1, len(data)), data)\n",
    "    plt.show()\n",
    "    \n",
    "# Adding white noise \n",
    "wn = np.random.randn(len(Audio_file))\n",
    "data_wn = Audio_file + 0.005*wn\n",
    "plot_time_series(data_wn)\n",
    "# We limited the amplitude of the noise so we can still hear the word even with the noise, \n",
    "#which is the objective\n",
    "ipd.Audio(data_wn, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shifting the sound\n",
    "data_roll = np.roll(Audio_file, 1600)\n",
    "plot_time_series(data_roll)\n",
    "ipd.Audio(data_roll, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "\n",
    "# Function to apply pitch speed variation\n",
    "def pitch_speed_variation(data, speed_factor):\n",
    "    return librosa.effects.pitch_shift(data, sr=16000, n_steps=speed_factor)\n",
    "\n",
    "# Function to apply noise injection\n",
    "def noise_injection(data, noise_level=0.5):\n",
    "    noise = np.random.normal(0, noise_level, len(data))\n",
    "    return data + noise\n",
    "\n",
    "# Function to apply time stretching\n",
    "def time_stretch(data, rate=1.0):\n",
    "    return librosa.effects.time_stretch(data, rate=rate)\n",
    "\n",
    "# Function to apply controlled pitch variation\n",
    "def controlled_pitch_variation(data, pitch_steps):\n",
    "    return librosa.effects.pitch_shift(data, sr=16000, n_steps=pitch_steps)\n",
    "\n",
    "# Apply augmentations\n",
    "pitch_speed_data = pitch_speed_variation(Audio_file, 0.2)  # 20% increase in pitch speed\n",
    "noisy_data = noise_injection(Audio_file, noise_level=0.5)\n",
    "time_stretched_data = time_stretch(Audio_file, rate=0.6)  # 20% time stretching\n",
    "controlled_pitch_data = controlled_pitch_variation(Audio_file, pitch_steps=2)\n",
    "\n",
    "# Plot and play the original and augmented signals\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.plot(Audio_file)\n",
    "plt.title('Original Audio')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.plot(pitch_speed_data)\n",
    "plt.title('Pitch Speed Variation')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.plot(noisy_data)\n",
    "plt.title('Noise Injection')\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.plot(time_stretched_data)\n",
    "plt.title('Time Stretching')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.plot(controlled_pitch_data)\n",
    "plt.title('Controlled Pitch Variation')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "ipd.Audio(Audio_file, rate=16000)\n",
    "ipd.Audio(pitch_speed_data, rate=16000)\n",
    "ipd.Audio(noisy_data, rate=16000)\n",
    "ipd.Audio(time_stretched_data, rate=16000)\n",
    "ipd.Audio(controlled_pitch_data, rate=16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "# Set Seaborn style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Function to visualize the waveform using Seaborn and Matplotlib\n",
    "def visualize_waveform(data, sr=16000, title=\"Waveform\"):\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    sns.lineplot(x=np.arange(len(data)) / sr, y=data)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.show()\n",
    "\n",
    "# Function to visualize the spectrogram using Seaborn and Matplotlib\n",
    "def visualize_spectrogram(data, sr=16000, title=\"Spectrogram\"):\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(data)), ref=np.max)\n",
    "    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', cmap='viridis')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Function to visualize the frequency distribution using Seaborn and Matplotlib\n",
    "def visualize_frequency_distribution(data, sr=16000, title=\"Frequency Distribution\"):\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    frequencies, amplitudes = librosa.magphase(librosa.stft(data))\n",
    "    plt.plot(frequencies, np.log1p(amplitudes.mean(axis=1)))  # Use mean(axis=1) to collapse the second dimension\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Log Amplitude')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Function to visualize the Mel Spectrogram using Seaborn and Matplotlib\n",
    "def visualize_melspectrogram(data, sr=16000, title=\"Mel Spectrogram\"):\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    mel_spec = librosa.feature.melspectrogram(y=data, sr=sr)  # Pass the audio data as 'y'\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    librosa.display.specshow(mel_spec_db, sr=sr, x_axis='time', y_axis='mel', cmap='viridis')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Function to visualize the Mel-Frequency Distribution using Seaborn and Matplotlib\n",
    "def visualize_melfrequency(data, sr=16000, title=\"Mel-Frequency Distribution\"):\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    mel_filters = librosa.filters.mel(sr=sr, n_fft=2048, n_mels=128, fmin=0.0, fmax=None, htk=False)\n",
    "    librosa.display.specshow(mel_filters, sr=sr, x_axis='linear', cmap='viridis')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Mel Bin')\n",
    "    plt.ylabel('Amplitude (dB)')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Load your audio file or use a random signal as an example\n",
    "# Example: audio_data, sr = librosa.load('your_audio_file.wav', sr=16000)\n",
    "# Make sure to load the audio file with the correct sample rate (sr)\n",
    "audio_data=Audio_file\n",
    "\n",
    "# Visualize waveform using Seaborn\n",
    "visualize_waveform(audio_data, sr=16000, title=\"Waveform\")\n",
    "\n",
    "# Visualize spectrogram using Seaborn\n",
    "visualize_spectrogram(audio_data, sr=16000, title=\"Spectrogram\")\n",
    "# Visualize frequency distribution using Seaborn\n",
    "visualize_frequency_distribution(audio_data, sr=16000, title=\"Frequency Distribution\")\n",
    "# Visualize Mel Spectrogram using Seaborn\n",
    "visualize_melspectrogram(audio_data, sr=16000, title=\"Mel Spectrogram\")\n",
    "\n",
    "# Visualize Mel-Frequency Distribution using Seaborn\n",
    "visualize_melfrequency(audio_data, sr=16000, title=\"Mel-Frequency Distribution\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
